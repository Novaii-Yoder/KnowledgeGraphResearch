{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473016ef-063b-449a-b326-9183b65f5beb",
   "metadata": {},
   "source": [
    "# Demo of Building and Using a KG in GPTs\n",
    "This code block will generate the KG from the texts and save it to a .json\n",
    "This block DOES NOT need to be ran every time. It will get expensive quick if you do. Only when you are creating a new KG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05775abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     30\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m apikey\n\u001b[0;32m---> 31\u001b[0m set_api_key(apikey)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create Graph\u001b[39;00m\n\u001b[1;32m     35\u001b[0m G, chunks \u001b[38;5;241m=\u001b[39m docs_to_kg(txt_file_paths, graph_file, pickle_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'set_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "from kg_builder import docs_to_kg, set_api_key\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# YOU CAN CHANGE THESE\n",
    "##################################################\n",
    "\n",
    "# This is an array of all documents you want to be put into the graph\n",
    "# Works with .txt, .pdf, and .json of the format [{\"image\": <image name>, \"description\":<text description of image>}]\n",
    "txt_file_paths = [\"test.txt\", \"test2.txt\"]\n",
    "\n",
    "# This is the file you want the graph to be saved to\n",
    "graph_file = \"Test.json\"\n",
    "\n",
    "# This is the file where the chunked documents will be stored\n",
    "pickle_file = \"Test.pkl\"\n",
    "\n",
    "# This is the file where your ChatGPT apikey is stored, is should be of the form \"sk-scvacct-XXXXXXXXXXXXXXX\"\n",
    "apikey_file = \"../serviceaccount.apikey\"\n",
    "##################################################\n",
    "\n",
    "# Open API key\n",
    "file = open(apikey_file, 'r')\n",
    "apikey = file.read().strip()\n",
    "file.close()\n",
    "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
    "set_api_key(apikey)\n",
    "\n",
    "\n",
    "# Create Graph\n",
    "G, chunks = docs_to_kg(txt_file_paths, graph_file, pickle_file)\n",
    "\n",
    "# Visualize the graph\n",
    "plt.figure(figsize=(24, 20))\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=100)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', font_weight='bold', node_size=300, font_size=5)\n",
    "\n",
    "# Write the relationships between nodes, gets ugly fast with large KGs\n",
    "edge_labels = nx.get_edge_attributes(G, 'type')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "\n",
    "plt.title(\"Knowledge Graph Visualization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05734e3f",
   "metadata": {},
   "source": [
    "# Search and Explanation\n",
    "The code block below will use the query given to search for relavent documents from the KG, and use them to generate an answer with ChatGPT. Then the same KG can be used to generate a path of reasoning between the question and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca26ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kg_builder import reasoning, KG_RAG, gpt_call\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from kg_builder import docs_to_kg\n",
    "\n",
    "\n",
    "# YOU CAN CHANGE THESE\n",
    "##################################################\n",
    "\n",
    "# This is the question you want to ask ChatGPT\n",
    "query = \"What does Mark do?\" # simple queries may not have very good explainations as they are usually just lookups in the text\n",
    "\n",
    "# This is the file you want the graph to be saved to\n",
    "graph_file = \"Test.json\"\n",
    "\n",
    "# This is the file where the chunked documents will be stored\n",
    "pickle_file = \"Test.pkl\"\n",
    "\n",
    "# This is the file where your ChatGPT apikey is stored, is should be of the form \"sk-scvacct-XXXXXXXXXXXXXXX\"\n",
    "apikey_file = \"../serviceaccount.apikey\"\n",
    "##################################################\n",
    "\n",
    "\n",
    "# Open API key\n",
    "file = open(apikey_file, 'r')\n",
    "apikey = file.read().strip()\n",
    "file.close()\n",
    "os.environ[\"OPENAI_API_KEY\"] = apikey\n",
    "\n",
    "\n",
    "# Open the \n",
    "with open(graph_file, 'r') as f:\n",
    "    graph_data = json.load(f)\n",
    "        \n",
    "G = nx.node_link_graph(graph_data)\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    chunks = pickle.load(file)\n",
    "\n",
    "# Outputs all documents used from the most similar nodes\n",
    "# Occasionally can be ALOT of documents\n",
    "docs = KG_RAG(G, query, chunks)\n",
    "\n",
    "#print(f\"Documents: \\n \")\n",
    "#for doc in docs:\n",
    "#    print(doc)\n",
    " \n",
    "ans = gpt_call(query, docs[:10])\n",
    "\n",
    "explanation, files_used, path = reasoning(G, chunks, query, ans)\n",
    "print(f\"Query:\\n   {query}\\n\\nGPT Answer:\\n   {ans}\\n\\nPath:\\n   {path}\\n\\nExplanation:\\n   {explanation}\\n\\nFiles Used: {files_used}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06144a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
